https://mp.weixin.qq.com/s?__biz=MzI1MzYzMjE0MQ==&mid=2247492622&idx=1&sn=f41fcb23b992b05566c9136eae7f5fa9&chksm=e9d32fecdea4a6faa15b00d0a1bce37627a473b0b80654ea5b4ccb007877133dcc2edee55a4e&mpshare=1&scene=1&srcid=0416pAViKOdwVCJ0430MCQMB&sharer_sharetime=1650120395333&sharer_shareid=7cbbcad39c685d480736bed5f05392d0&key=a7e92fd1e02b34e1f69cf95d4d12863a4dc159ec655d8c53e93d06a2e3aa89b67d4662b040893755e5a86b339daca8579d5ab07bb7a14b6cd958759b29770ace84c2cb14e18602b0968fcecb313ad0314cd592e05225b505269b9aa5681ea68fa814bc646805de82d070d9aff4ab716a09092afcb49a307af4e4618ce96f7410&ascene=1&uin=Mjc1MjQzMTM1Mg%3D%3D&devicetype=Windows+XP&version=62060841&lang=zh_CN&exportkey=A9Wb7o2rxghmOuWtZ5%2F%2FW3Y%3D&acctmode=0&pass_ticket=ff3%2FrMWtJIAb1XWvFEaucnPJMA8QAhWff2kXaJzNO%2BiJSO9urIVb6tQRwtajIB80&wx_header=0

看推荐时候刚好看到这篇. 大致了解字节这边实现. 
然后类比小米有品这边实现. 大致实现类似的. 不过从架构上讲有品这边输出架构实现文档一般会基于各组之间业务联动核心考虑服务高可用.
联动意思是, 考虑优惠整体, 例如我们这边优惠大组包括, 优惠组, 优惠券组, 风控算法组, 风控工程组.
当然也包括中台内商品, 订单组, 购物车联动交互也会在设计中出现. 

观看上面文章, 这里讨论下有品这边优惠券组业务, 他提供给交易下单用的功能和优惠组紧绑定. 优惠组屏蔽交易和优惠券组沟通细节. 这个不同公司架构不一样, 有的分开, 小米有品这边有多套电商体系(小米商城, 小米有品, 有鱼, 米家等等, 多团队维护), 两种都有, 这边以优惠对交易屏蔽优惠券细节讲. 

整体看上面文档字节和有品两边实现很类似. mysql 最准数据, redis 是存储一份全量数据模板(过期券模板+有效券模板), 本地存有效券.
本地通过 zk 通知要更新那些券模板数据(运营修改券模板信息, 然后 zk 通知). 这边有 15min 兜底, 从 mysql 中拉取最新数据. 

优惠券模板大头是商品. 我们对于这个做了一些处理. 首先用ES做了倒排索引(劵里内容和券模板反向索引给B端用的) . 然后我们大促时候
有个全场(这个全场比较特殊, 不是真全场, 而是99%商品可用)劵概念. 券模板3000-5000种, 商品又几十万, 乘积非常可怕. 所以这里需要业务和产品推动双方对技术边界裁剪. 我们没法提供真的全场券功能. 每次大促我们会和运营产品定好 全场商品镜像. 全场券关联这个镜像来解决这个问题.
然后扣库存也不是扣库存是加已经使用的数. 总库存是配置的, 当库存不够发送消息然后消费消息通知运营补库存等. 

然后涉及另外一个问题. 如何保证一致性. 关于一致性优惠券和优惠在一块设计的. 
一致性保障环节很多, 例如前面说的 zk 通知, 15min 重建有效数据兜底. 这些大部分下单前保证. 下单过程中. 依赖于 redis 分布式锁. 
(我们这里是 挨个对redis上资源加锁, 这是慢的地方) 如果中途有活动库存不足或其他失败. 我们会执行补偿流程. 

补偿是以数据库(分库保证数据库不是瓶颈)最初配置信息和生成信息还有redis 信息为准. 如果我们这台机器刚好挂了. 我们兜底方案是. 有专门补偿服务器, 通过订单状态来完成优惠资源最终一致性. 
并且补偿服务是高可用抢任务架构, 任何时候只有一台在运行.

然后补充个细节, 关于 redis 集群超时. 这个在这边之前遇到, 我们排查很久是使用 redis 库 core 存在老bug. 我们更换之后,再也没有遇到. 
相关 redis 集群问题我们联合 DBA 查过几次, redis 集群很稳定, 往往业务使用存在问题, 泄露, 不合格相关库等. 这边也有单独弄个分组出来, 
不过这个分组是安慰作用(保证分组机器配置更好, 带宽更好). 因为下单时候一定用的相同数据库. 
关于突发流量例如秒杀业务我们可能和外面不一样, 因为雷系很节省, 机器很少. 我们应对突发流量做法, 其实和运营同学一块配合. 提前通知, 还有我们会观察图表
流量, 往往是有规律的, 大部分特殊时刻会有1min高峰. 在有规律地方我们在网关上写好定时任务, 例如提前 10min 扩容, 然后借助网关能力缩容. 业务上写好限流代码. 
同样因为机器很少, 我们观察有些做活动特别热门商品往往真实活动库存很少, 所以很多都是无效抢购浪费核心服务资源. 所以我们中间环节加了一个服务发令牌环节, 为核心服务挡了一层. 
如果超级热门会通过提前预约等. 业务多变, 很多优化是很多部门产品运营测试研发运维等联动的. 不同公司策略和形成解决方案不一样, 优惠大组业务很多, 上面说了一下我们这边大致简单做法. 


